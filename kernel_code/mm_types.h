struct page
{
    unsigned long flags;		/* Atomic flags, some possibly updated asynchronously */
    /*
    * Five words (20/40 bytes) are available in this union.
    * WARNING: bit 0 of the first word is used for PageTail(). That
    * means the other users of this union MUST NOT use the bit to
    * avoid collision and false-positive PageTail().
    */
    union
    {
        /* Page cache and anonymous pages */
        struct
        {
            /**
             * @lru: Pageout list, eg. active_list protected by
             * lruvec->lru_lock.  Sometimes used as a generic list
             * by the page owner.
             */
            union
            {
                struct list_head lru;

                /* Or, for the Unevictable "LRU list" slot */
                struct
                {
                    /* Always even, to negate PageTail */
                    void* __filler;
                    /* Count page's or folio's mlocks */
                    unsigned int mlock_count;
                };

                /* Or, free page */
                struct list_head buddy_list;
                struct list_head pcp_list;
            };
            /* See page-flags.h for PAGE_MAPPING_FLAGS */
            struct address_space* mapping;
            union
            {
                pgoff_t index;		/* Our offset within mapping. */
                unsigned long share;	/* share count for fsdax */
            };
            /**
             * @private: Mapping-private opaque data.
             * Usually used for buffer_heads if PagePrivate.
             * Used for swp_entry_t if PageSwapCache.
             * Indicates order in the buddy system if PageBuddy.
             */
            unsigned long private;
        };
        /* page_pool used by netstack */
        struct
        {
            /**
             * @pp_magic: magic value to avoid recycling non
             * page_pool allocated pages.
             */
            unsigned long pp_magic;
            struct page_pool* pp;
            unsigned long _pp_mapping_pad;
            unsigned long dma_addr;
            atomic_long_t pp_ref_count;
        };
        /* Tail pages of compound page */
        struct
        {
            unsigned long compound_head;	/* Bit zero is set */
        };
        /* ZONE_DEVICE pages */
        struct
        {
            /** @pgmap: Points to the hosting device page map. */
            struct dev_pagemap* pgmap;
            void* zone_device_data;
            /*
             * ZONE_DEVICE private pages are counted as being
             * mapped so the next 3 words hold the mapping, index,
             * and private fields from the source anonymous or
             * page cache page while the page is migrated to device
             * private memory.
             * ZONE_DEVICE MEMORY_DEVICE_FS_DAX pages also
             * use the mapping, index, and private fields when
             * pmem backed DAX files are mapped.
             */
        };

        /** @rcu_head: You can use this to free a page by RCU. */
        struct rcu_head rcu_head;
    };

    union
    {
        /* This union is 4 bytes in size. */
        /*
        * If the page can be mapped to userspace, encodes the number
        * of times this page is referenced by a page table.
        */
        atomic_t _mapcount;

        /*
         * If the page is neither PageSlab nor mappable to userspace,
         * the value stored here may help determine what this page
         * is used for.  See page-flags.h for a list of page types
         * which are currently stored here.
         */
        unsigned int page_type;
    };
    /* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */
    atomic_t _refcount;

    #ifdef CONFIG_MEMCG
    unsigned long memcg_data;
    #endif

    /*
     * On machines where all RAM is mapped into kernel address space,
     * we can simply calculate the virtual address. On machines with
     * highmem some memory is mapped into kernel virtual memory
     * dynamically, so we need a place to store that address.
     * Note that this field could be 16 bits on x86 ... ;)
     *
     * Architectures with slow multiplication can define
     * WANT_PAGE_VIRTUAL in asm/page.h
     */
    #if defined(WANT_PAGE_VIRTUAL)
    void* virtual;			/* Kernel virtual address (NULL if
                       not kmapped, ie. highmem) */
    #endif /* WANT_PAGE_VIRTUAL */

    #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
    int _last_cpupid;
    #endif

    #ifdef CONFIG_KMSAN
    /*
     * KMSAN metadata for this page:
     *  - shadow page: every bit indicates whether the corresponding
     *    bit of the original page is initialized (0) or not (1);
     *  - origin page: every 4 bytes contain an id of the stack trace
     *    where the uninitialized value was created.
     */
    struct page* kmsan_shadow;
    struct page* kmsan_origin;
    #endif
} _struct_page_alignment;